IQR(Final2017$'2014')
t.test(Final2017$'2014' , mu = 1010 , conf.level = 0.9, alternative="greater")
var.test(Final2017$'2013',Final2017%'2014')
var.test(Final2017$'2013', Final2017%'2014')
data1 <- Final2017$'2013'
data2 <- Final2017$'2014'
var.test(data1,data2)
t.test(data1,data2, conf.level=0.95, alternative="two.sided")
Final<-read_excel("/Users/timothylytkine/Desktop/Final2017.xlsx")
Final2017<-as.data.frame(Final)
#A Histogram and boxplot for average scores in 2013
hist(Final2017$'2013')
boxplot(Final2017$'2013')
IQR(Final2017$'2014')
t.test(Final2017$'2014' , mu = 1010 , conf.level = 0.9, alternative="greater")
data1 <- Final2017$'2013'
data2 <- Final2017$'2014'
t.test(data1,data2, conf.level=0.95, alternative="two.sided")
install.packages("party")
ctree(formula,data)
library(party)
install.packages(party)
install.packages("party")
train <- data.frame(ClaimID = c(1,2,3),)
train <- data.frame(ClaimID = c(1,2,3),
RearEnd = c(TRUE, FALSE, TRUE),
Fraud = c(TRUE, FALSE, TRUE))
train
ClaimID RearEnd Fraud
1       1    TRUE  TRUE
2       2   FALSE FALSE
3       3    TRUE  TRUE
library(rpart)
mytree <- rpart(Fraud ~ RearEnd, data = train,)
method = "class")
method = "class"
)
mytree <- rpart(Fraud ~ RearEnd, data = train, method = "class")
mytree
n = 3
node), split, n, loss, y
train <- data.frame(ClaimID = c(1,2,3),)
train <- data.frame(ClaimID = c(1,2,3),
2
RearEnd = c(TRUE, FALSE, TRUE),
3
Fraud = c(TRUE, FALSE, TRUE))
train <- data.frame(ClaimID = c(1,2,3),
RearEnd = c(TRUE, FALSE, TRUE),
Fraud = c(TRUE, FALSE, TRUE))
train
library(rpart)
mytree <- rpart(Fraud ~ RearEnd, data = train,)
mytree <- rpart(Fraud ~ RearEnd, data = train, method = "class")
mytree
mytree <- rpart(Fraud ~ RearEnd, data = train, method = "class", minsplit = 2, minbucket = 1)
mytree
library(rattle)
install.packages("rattle")
y
y
y
y
library(rattle)
install.packages("rattle")
install.packages(c("animation", "BH", "bit", "bit64", "broom", "cairoDevice", "car", "cluster", "colorspace", "corrplot", "curl", "DBI", "dendextend", "devtools", "digest", "dplyr", "evaluate", "factoextra", "fpc", "ggplot2", "ggrepel", "git2r", "gridExtra", "highr", "htmlwidgets", "httpuv", "httr", "jsonlite", "knitr", "lazyeval", "lme4", "memoise", "munsell", "NLP", "openintro", "openssl", "plotrix", "psych", "quantreg", "R6", "Rcpp", "RcppEigen", "readxl", "reshape2", "rgl", "rjson", "rstudioapi", "scales", "scatterplot3d", "shiny", "sourcetools", "stringi", "stringr", "tibble", "tidyr", "tm", "visreg", "withr", "XML", "yaml"))
View(train)
View(train)
load("/Volumes/NO NAME/permits_accident_data_2013_Present.csv")
load("~/Desktop/Predictive Modeling Project/permits_accident_data_2013_Present.csv")
library(xlsx)
install.packages("xlsx")
install.packages("xlsx")
install.packages("xlsx")
library(xlsx)
accident_data <- read.xlsx("/Users/timothylytkine/Desktop/Predictive Modeling Project/permits_accident_data_2013_Present.xlsx",1)
accident_data <- read.xlsx("/Users/timothylytkine/Desktop/Predictive Modeling Project/permits_accident_data_2013_Present.xlsx",1)
accident_data <- read.xlsx("/Users/timothylytkine/Desktop/Predictive Modeling Project/permits_accident_data_2013_Present.xlsx",1)
MyData <- read.csv(file="/Users/timothylytkine/Desktop/Predictive Modeling Project/permits_accident_data_2013_Present.csv", header=TRUE, sep=",")
permits_accident_data_2013_Present <- read.csv(file="/Users/timothylytkine/Desktop/Predictive Modeling Project/permits_accident_data_2013_Present.csv", header=TRUE, sep=",")
View(permits_accident_data_2013_Present)
View(MyData)
View(permits_accident_data_2013_Present)
library(rpart)
View(train)
View(mytree)
View(permits_accident_data_2013_Present)
View(permits_accident_data_2013_Present)
View(permits_accident_data_2013_Present)
View(MyData)
mytree <- rpart(Accident ~ Proposed.Stories + Job.Type + Borough + Square.Footage + General.Contractor + Cost.Estimate , data = MyData, method = "class", minsplit = 2, minbucket = 1)
View(permits_accident_data_2013_Present)
View(permits_accident_data_2013_Present)
View(permits_accident_data_2013_Present)
View(permits_accident_data_2013_Present)
View(permits_accident_data_2013_Present)
MyData$Accident_Pred <- predict(mytree, newdata = MyData, type="class")
MyData$Accident_Prob <- predict(mytree, newdata = MyData, type="prob")
printcp(mytree)
MyData2 <- permits_accident_data_2013_Present
MyData2
library(dplyr)
train<-sample_frac(MyData2,0.8)
sid<-as.numeric(rownames(train))
test<-a[-sid,]
test<-MyData2[-sid,]
train <- data.frame(ClaimID = c(1,2,3), RearEnd = c(TRUE,FALSE,TRUE), Fraud = c(TRUE,FALSE,TRUE))
train
library(dplyr)
train<-sample_frac(MyData2,0.8)
sid<-as.numeric(rownames(train))
test<-a[-sid,]
test<-MyData2[-sid,]
training <- train
testing <- test
train <- data.frame(ClaimID = c(1,2,3), RearEnd = c(TRUE,FALSE,TRUE), Fraud = c(TRUE,FALSE,TRUE))
train
train
testing
testing
train
library(rpart)
mytree <- rpart(Fraud ~ RearEnd, data = train, method = "class")
mytree
n = 3
n <-
0
n = 3
mytree <- rpart(Fraud ~ RearEnd, data = train, method = "class", minsplit = 2, minbucket = 1)
mytree
library(rattle)
install.packages("rattle")
install.packages("RGtk2")
install.packages('versions')
install.packages("https://cran.r-project.org/src/contrib/Archive/RGtk2/RGtk2_2.20.30.tar.gz", repos=NULL)
install.packages("RGtk2", depen=T)
install.packages("RGtk2", depen=T, type="source")
install.packages("RGtk2", depen=T)
install.packages("RGtk2", depen=T, type="source")
install.packages("RGtk2", depen=T, type="source")
library(gWidgets)
install.packages("gWidgets")
library(gWidgets)
options(guiToolkit("RGtk2"))
options(guiToolkit("RGtk2")
options(guiToolkit("RGtk2")
options(guiToolkit="RGtk2")
win <- gwindow("test")
glabel("test label", container = win)
glabel("test label", container = win)
install.packages(c("animation", "BH", "bit", "bit64", "broom", "cairoDevice", "car", "cluster", "colorspace", "corrplot", "curl", "DBI", "dendextend", "devtools", "digest", "dplyr", "evaluate", "factoextra", "fpc", "ggplot2", "ggrepel", "git2r", "gridExtra", "highr", "htmlwidgets", "httpuv", "httr", "jsonlite", "knitr", "lazyeval", "lme4", "memoise", "munsell", "NLP", "openintro", "openssl", "plotrix", "psych", "quantreg", "R6", "Rcpp", "RcppEigen", "readxl", "reshape2", "rgl", "rjson", "rstudioapi", "scales", "scatterplot3d", "shiny", "sourcetools", "stringi", "stringr", "tibble", "tidyr", "tm", "visreg", "withr", "XML", "yaml"))
system('brew install gtk+')
local({
if (Sys.info()[['sysname']] != 'Darwin') return()
.Platform$pkgType = 'mac.binary.el-capitan'
unlockBinding('.Platform', baseenv())
assign('.Platform', .Platform, 'package:base')
lockBinding('.Platform', baseenv())
options(
pkgType = 'both', install.packages.compile.from.source = 'always',
repos = 'https://macos.rbind.org'
)
})
install.packages(c('RGtk2', 'cairoDevice', 'rattle'))
library(rattle)
install.packages("rattle")
MyData$Accident_Prob <- predict(mytree, newdata = MyData, type="prob")
install.packages("ggplot2")
install.packages("magrittr")
install.packages("RGtk2")
# Data set before being split
MyData <- read.csv(file="/Users/timothylytkine/Desktop/Predictive Modeling Project/permits_accident_data_2013_Present.csv", header=TRUE, sep=",")
# Copies of original data set to use later
MyData1 <- MyData
MyData2 <- MyData
MyData3 <- MyData
# load r part library
library(rpart)
View(testing)
View(training)
# use copy of original data set to split into training and testing data set
training_set <- sample_frac(MyData1,0.8)
sid<-as.numeric(rownames(training_set))
testing_set<-MyData1[-sid,]
# 80 percent of data for training
training_set
# 20 percent of data for testing
testing_set
mytree <- rpart(Accident ~ Proposed.Stories + Job.Type + Borough + Square.Footage + General.Contractor + Cost.Estimate , data = training_set, method = "class", minsplit = 2, minbucket = 1)
# use copy of original data set to split into training and testing data set
training_set <- sample_frac(MyData1,0.8)
# load dplyr library
library(dplyr)
# use copy of original data set to split into training and testing data set
training_set <- sample_frac(MyData1,0.8)
mytree <- rpart(Accident ~ Proposed.Stories + Job.Type + Borough + Square.Footage + General.Contractor + Cost.Estimate , data = training_set, method = "class", minsplit = 2, minbucket = 1)
training_set$Accident_Pred <- predict(mytree, newdata = training_set, type="class")
training_set$Accident_Pred <- predict(mytree, newdata = training_set, type="prob")
printcp(mytree)
mytree
View(testing_set)
View(training_set)
printcp(mytree)
# Data set before being split
MyData <- read.csv(file="/Users/timothylytkine/Desktop/Predictive Modeling Project/permits_accident_data_2013_Present.csv", header=TRUE, sep=",")
# Copies of original data set to use later
MyData1 <- MyData
MyData2 <- MyData
MyData3 <- MyData
# load r part library
library(rpart)
# create tree using unsplit data set
mytree <- rpart(Accident ~ Proposed.Stories + Job.Type + Borough + Square.Footage + General.Contractor + Cost.Estimate , data = MyData, method = "class", minsplit = 2, minbucket = 1)
# Syntax for binary prediction and probability
# unsplit data set
MyData$Accident_Pred <- predict(mytree, newdata = MyData, type="class")
MyData$Accident_Pred <- predict(mytree, newdata = MyData, type="prob")
printcp(mytree)
# load dplyr library
library(dplyr)
# use copy of original data set to split into training and testing data set
training_set <- sample_frac(MyData1,0.8)
sid<-as.numeric(rownames(training_set))
testing_set<-MyData1[-sid,]
# 80 percent of data for training
training_set
# 20 percent of data for testing
testing_set
library(rattle)
library(rpart.plot)
library(RColorBrewer)
test_tree <- rpart(Accident ~ Proposed.Stories + Job.Type + Borough + Square.Footage + General.Contractor + Cost.Estimate , data = training_set, method = "class", minsplit = 2, minbucket = 1)
training_set$Accident_Pred <- predict(test_tree, newdata = training_set, type="class")
training_set$Accident_Pred <- predict(test_tree, newdata = training_set, type="prob")
printcp(test_tree)
test_tree
summary(test_tree)
fitness <- read.table("/Users/timothylytkine/Desktop/Work/Decision-Tree-Model-in-R-/fitnessAppLog.csv",sep=",",header=T)
library("rpart")
treeAnalysis <- rpart(PayOrNot~Incomes+GymVisits+State,data=fitness)
treeAnalysis
install.packages("rpart.plot")
library("rpart.plot")
rpart.plot(treeAnalysis,extra=4)
ls()
rm()
ls
ls()
View(fitness)
First()
ls()
rm(fitness)
ls()
rn(MyData)
rm(all)
rm(MyData)
rm(MyData1)
rm(MyData2)
ls()
rm(MyData3)
ls
ls
ls9)
ls()
rm(mytree)
rm(permits_accident_data_2013_Present)
ls()
ls
ls()
rm(n)
rm(train)
rm(z)
rm(sid)
rm(training)
rm(test)
rm(training_set)
rm(test_tree)
rm(treeAnalysis)
rm(testing)
rm(x)
rm(testing_set)
rm(y)
ls()
rm(character(0))
ls()
a = 49
sqrt(a)
a = "The dog ate my homework"
sub("dog","cat",a)
a = (1+1==3)
a
a = c(1,2,3)
a*2
a<-matrix(data=0,nr=1,nc=3)
a
doe = list(name="john",age=28,married=F)
doe$name
doe$age
a
addPercent <- function(x)
{
percent <-round(x*100,digits=1)
result <- paste(percent,"%",sep="")
return result
}
addPercent <- function(x)
{
percent <-round(x*100,digits=1)
result <- paste(percent,"%",sep="")
return(result)
}
install.packages("readr")
library(readr)
while(1){
print("Yo")
}
# take input from the user
num = as.integer(readline(prompt="Enter a number: "))
# check if the number is negative, positive
if (num < 0)
{
print("Sorry, factorial does not exist for negative numbers")
}
else if(num == 0)
{
print("The factorial of 0 is 1")
}
else
{
for(i in 1:num)
{
factorial = factorial * i
}
}
print(paste("The factorial of",num,"is",factorial))
}
# take input from the user
num = as.integer(readline(prompt="Enter a number: "))
factorial = 1
# check if the number is negative, positive
if (num < 0)
{
print("Sorry, factorial does not exist for negative numbers")
}
else if(num == 0)
install.packages("readr")
library(readr)
install.packages("dplyr")
install.packages("dplyr")
install.packages(ggplot2)
install.packages(ggplot)
install.packages("ggplot2")
installed.packages("esquisse")
test_expression = "yes"
if(test_expression){
print("Yes")
} else {
print("No")
}
test_expression = "yes"
if (test_expression){
print("Yes")
} else {
print("No")
}
test_expression = TRUE
if (test_expression){
print("Yes")
} else {
print("No")
}
test_expression = TRUE
if (test_expression){
print("Yes")
} else {
print("No")
}
install.packages("igraph")
install.packages("sna")
plot(a)
plot(doe)
library(data.table)
library(ggplot2)
library(gridExtra)
library(corrplot)
library(rpart)
library(randomForest)
library(stepPlr)
library(C50)
library(plyr)
library(MASS)
library(caret)
library(caretEnsemble)
library(dplyr)
library(plotly)
# make subplots
p <- subplot(
# histogram (counts) of gear
plot_ly(d, x = ~factor(gear)) %>%
add_histogram(color = I("grey50")),
# scatterplot of disp vs mpg
scatterplot,
titleX = T
)
# define a shared data object
d <- SharedData$new(mtcars)
g <- ggplot(txhousing, aes(x = date, y = sales, group = city)) +
geom_line(alpha = 0.4)
g
ggplotly(g, tooltip = c("city"))
g <- txhousing %>%
# group by city
group_by(city) %>%
# initiate a plotly object with date on x and median on y
plot_ly(x = ~date, y = ~median) %>%
# add a line plot for all texan cities
add_lines(name = "Texan Cities", hoverinfo = "none",
type = "scatter", mode = "lines",
line = list(color = 'rgba(192,192,192,0.4)')) %>%
# plot separate lines for Dallas and Houston
add_lines(name = "Houston",
data = filter(txhousing,
city %in% c("Dallas", "Houston")),
hoverinfo = "city",
line = list(color = c("red", "blue")),
color = ~city)
g
library(crosstalk)
# define a shared data object
d <- SharedData$new(mtcars)
# make a scatterplot of disp vs mpg
scatterplot <- plot_ly(d, x = ~mpg, y = ~disp) %>%
add_markers(color = I("navy"))
# define two subplots: boxplot and scatterplot
subplot(
# boxplot of disp
plot_ly(d, y = ~disp) %>%
add_boxplot(name = "overall",
color = I("navy")),
# scatterplot of disp vs mpg
scatterplot,
shareY = TRUE, titleX = T) %>%
layout(dragmode = "select")
# make subplots
p <- subplot(
# histogram (counts) of gear
plot_ly(d, x = ~factor(gear)) %>%
add_histogram(color = I("grey50")),
# scatterplot of disp vs mpg
scatterplot,
titleX = T
)
layout(p, barmode = "overlay")
library(networkD3)
data(MisLinks, MisNodes)
head(MisLinks, 3)
head(MisNodes, 3)
forceNetwork(Links = MisLinks, Nodes = MisNodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
Group = "group", opacity = 0.9, Nodesize = 3,
linkDistance = 100, fontSize = 20)
# Scatterplot
gg <- ggplot(midwest, aes(x=area, y=poptotal)) +
geom_point(aes(col=state, size=popdensity)) +
geom_smooth(method="loess", se=F) +
xlim(c(0, 0.1)) +
ylim(c(0, 500000)) +
labs(subtitle="Area Vs Population",
y="Population",
x="Area",
title="Scatterplot",
caption = "Source: midwest")
plot(gg)
install.packages("cowplot")  # a gganimate dependency
install.packages("devtools")
devtools::install_github("https://github.com/thomasp85/gganimate/releases/tag/v0.1.1")
install.packages("gapminder")
library(ggplot2)
library(gganimate)
library(gapminder)
theme_set(theme_bw())  # pre-set the bw theme.
g <- ggplot(gapminder, aes(gdpPercap, lifeExp, size = pop, frame = year)) +
geom_point() +
geom_smooth(aes(group = year),
method = "lm",
show.legend = FALSE) +
facet_wrap(~continent, scales = "free") +
scale_x_log10()  # convert to log scale
gganimate(g, interval=0.2)
setwd("~/Desktop/Data Science/BigData /Project3BigData")
# Load text file
project_data <- read.table("DrJekyllAndMrHyde.txt")
# Load text file
project_data <- read.delim("DrJekyllAndMrHyde.txt")
project_data
nrow(project_data)
ncol(project_data)
head(project_data)
# Create a VCorpus - I
getwd()
install.packages("tm")
library(tm)
dataCorpus <- VCorpus(DirSource("DrJekyllAndMrHyde.txt",ignore.case = TRUE,mode="text"))
dataCorpus <- VCorpus(DirSource("./DrJekyllAndMrHyde.txt",ignore.case = TRUE,mode="text"))
dataCorpus <- VCorpus(DirSource(./DrJekyllAndMrHyde.txt,ignore.case = TRUE,mode="text"))
dataCorpus <- VCorpus(DirSource("./DrJekyllAndMrHyde.txt",ignore.case = TRUE,mode="text"))
dataCorpus <- VCorpus(DirSource("/Users/timothylytkine/Desktop/Data Science/BigData /Project3BigData/DrJekyllAndMrHyde.txt",ignore.case = TRUE,mode="text"))
dataCorpus <- VCorpus(DirSource(".",ignore.case = TRUE,mode="text"))
dataCorpus
dataCorpus
inspect(dataCorpus)
source('~/Desktop/Data Science/BigData /Project3BigData/Project3.R')
