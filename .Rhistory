{
print("Sorry, factorial does not exist for negative numbers")
}
else if(num == 0)
{
print("The factorial of 0 is 1")
}
else
{
for(i in 1:num)
{
factorial = factorial * i
}
}
print(paste("The factorial of",num,"is",factorial))
}
# take input from the user
num = as.integer(readline(prompt="Enter a number: "))
factorial = 1
# check if the number is negative, positive
if (num < 0)
{
print("Sorry, factorial does not exist for negative numbers")
}
else if(num == 0)
install.packages("readr")
library(readr)
install.packages("dplyr")
install.packages("dplyr")
install.packages(ggplot2)
install.packages(ggplot)
install.packages("ggplot2")
installed.packages("esquisse")
test_expression = "yes"
if(test_expression){
print("Yes")
} else {
print("No")
}
test_expression = "yes"
if (test_expression){
print("Yes")
} else {
print("No")
}
test_expression = TRUE
if (test_expression){
print("Yes")
} else {
print("No")
}
test_expression = TRUE
if (test_expression){
print("Yes")
} else {
print("No")
}
install.packages("igraph")
install.packages("sna")
plot(a)
plot(doe)
library(data.table)
library(ggplot2)
library(gridExtra)
library(corrplot)
library(rpart)
library(randomForest)
library(stepPlr)
library(C50)
library(plyr)
library(MASS)
library(caret)
library(caretEnsemble)
library(dplyr)
library(plotly)
# make subplots
p <- subplot(
# histogram (counts) of gear
plot_ly(d, x = ~factor(gear)) %>%
add_histogram(color = I("grey50")),
# scatterplot of disp vs mpg
scatterplot,
titleX = T
)
# define a shared data object
d <- SharedData$new(mtcars)
g <- ggplot(txhousing, aes(x = date, y = sales, group = city)) +
geom_line(alpha = 0.4)
g
ggplotly(g, tooltip = c("city"))
g <- txhousing %>%
# group by city
group_by(city) %>%
# initiate a plotly object with date on x and median on y
plot_ly(x = ~date, y = ~median) %>%
# add a line plot for all texan cities
add_lines(name = "Texan Cities", hoverinfo = "none",
type = "scatter", mode = "lines",
line = list(color = 'rgba(192,192,192,0.4)')) %>%
# plot separate lines for Dallas and Houston
add_lines(name = "Houston",
data = filter(txhousing,
city %in% c("Dallas", "Houston")),
hoverinfo = "city",
line = list(color = c("red", "blue")),
color = ~city)
g
library(crosstalk)
# define a shared data object
d <- SharedData$new(mtcars)
# make a scatterplot of disp vs mpg
scatterplot <- plot_ly(d, x = ~mpg, y = ~disp) %>%
add_markers(color = I("navy"))
# define two subplots: boxplot and scatterplot
subplot(
# boxplot of disp
plot_ly(d, y = ~disp) %>%
add_boxplot(name = "overall",
color = I("navy")),
# scatterplot of disp vs mpg
scatterplot,
shareY = TRUE, titleX = T) %>%
layout(dragmode = "select")
# make subplots
p <- subplot(
# histogram (counts) of gear
plot_ly(d, x = ~factor(gear)) %>%
add_histogram(color = I("grey50")),
# scatterplot of disp vs mpg
scatterplot,
titleX = T
)
layout(p, barmode = "overlay")
library(networkD3)
data(MisLinks, MisNodes)
head(MisLinks, 3)
head(MisNodes, 3)
forceNetwork(Links = MisLinks, Nodes = MisNodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
Group = "group", opacity = 0.9, Nodesize = 3,
linkDistance = 100, fontSize = 20)
# Scatterplot
gg <- ggplot(midwest, aes(x=area, y=poptotal)) +
geom_point(aes(col=state, size=popdensity)) +
geom_smooth(method="loess", se=F) +
xlim(c(0, 0.1)) +
ylim(c(0, 500000)) +
labs(subtitle="Area Vs Population",
y="Population",
x="Area",
title="Scatterplot",
caption = "Source: midwest")
plot(gg)
install.packages("cowplot")  # a gganimate dependency
install.packages("devtools")
devtools::install_github("https://github.com/thomasp85/gganimate/releases/tag/v0.1.1")
install.packages("gapminder")
library(ggplot2)
library(gganimate)
library(gapminder)
theme_set(theme_bw())  # pre-set the bw theme.
g <- ggplot(gapminder, aes(gdpPercap, lifeExp, size = pop, frame = year)) +
geom_point() +
geom_smooth(aes(group = year),
method = "lm",
show.legend = FALSE) +
facet_wrap(~continent, scales = "free") +
scale_x_log10()  # convert to log scale
gganimate(g, interval=0.2)
# install.packages("tm")
# install.packages("textreuse")
# install.packages("wordnet")
# install.packages("zipfR")
# install.packages("rjJava")
library(devtools)
library(textreuse)
library(wordnet)
library(tm)
library(zipfR)
brew install wordnet
install.packages("wordnet")
install.packages("wordnet")
library(wordnet)
setDict("/usr/local/Cellar/wordnet/3.1")
initDict()
library(wordnet)
library(wordnet)
library(tm)
library(zipfR)
# Load text file
project_data <- read.delim("text/DrJekyllAndMrHyde.txt")
setwd("~/Desktop/DataScience/BigData /Project3BigData")
# Load text file
project_data <- read.delim("text/DrJekyllAndMrHyde.txt")
project_data
# Check numrows
nrow(project_data)
library(zipfR)
# Load text file
project_data <- read.delim("text/DrJekyllAndMrHyde.txt")
project_data
# Check numrows
nrow(project_data)
# Check head
head(project_data)
# Create a VCorpus - I (Voltatile corpus aka collection of documents containing natural language text
# using the infrastructure of the package tm)
# Contains all files in working directory
dataCorpus <- VCorpus(DirSource("text/",ignore.case = TRUE,mode="text"))
dataCorpus
inspect(dataCorpus)
str(dataCorpus)
data1 <- dataCorpus[[1]]
data1
dataDTM <- DocumentTermMatrix(dataCorpus)
dataDTM
inspect(dataDTM[1,100])
dataTDM <- TermDocumentMatrix(dataCorpus)
dataTDM
inspect(dataTDM[10,1])
data1TF <- termFreq(data1)
data1TF
data1DF <- as.data.frame(data1TF)
data1DF
dataLow <- tm_map(dataCorpus,content_transformer(tolower))
dataLow
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*","",x)
dataCl <- tm_map(dataLow,content_transformer(removeNumPunct))
toSpace <- content_transformer(function (x,pattern) gsub(pattern,"",x))
docs <- tm_map(dataCl,toSpace,"/")
docs <- tm_map(dataCl,toSpace,"@")
docs <- tm_map(dataCl,toSpace,"\\|")
myStopWords <- c(stopwords('english'))
myStopWords
SA
inspect(dataCorpus)
str(dataCorpus)
data1 <- dataCorpus[[1]]
data1
dataDTM <- DocumentTermMatrix(dataCorpus)
dataDTM
inspect(dataDTM[1,100])
dataTDM <- TermDocumentMatrix(dataCorpus)
dataTDM
inspect(dataTDM[10,1])
data1TF <- termFreq(data1)
data1TF
data1DF <- as.data.frame(data1TF)
dataLow <- tm_map(dataCorpus,content_transformer(tolower))
data1DF
dataCl <- tm_map(dataLow,content_transformer(removeNumPunct))
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*","",x)
dataCl <- tm_map(dataLow,content_transformer(removeNumPunct))
dataLow <- tm_map(dataCorpus,content_transformer(tolower))
dataLow
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*","",x)
dataCl <- tm_map(dataLow,content_transformer(removeNumPunct))
toSpace <- content_transformer(function (x,pattern) gsub(pattern,"",x))
dataCl <- tm_map(dataCl,toSpace,"/")
dataCl <- tm_map(dataCl,toSpace,"@")
dataCl <- tm_map(dataCl,toSpace,"\\|")
myStopWords <- c(stopwords('english'))
myStopWords
dataStop <- tm_map(dataCl,removeWords,myStopWords)
inspect(dataStop[1:3])
dataStop
dataStop[1]
dataStop[1,1]
dataStop[0,1]
dataStop[1]
dataStop[2]
dataStop[3]
dataStop
str(dataStop)
dataStop$DrJekyllAndMrHyde.txt
dataCl <- tm_map(dataLow,content_transformer(removeNumPunct))
dataCl
dataLow <- tm_map(dataCorpus,content_transformer(tolower))
dataLow
dataLow <- tm_map(data1DF,content_transformer(tolower))
dataLow <- tm_map(dataTDM,content_transformer(tolower))
dataLow <- tm_map(dataDTM,content_transformer(tolower))
dataLow <- tm_map(data1,content_transformer(tolower))
dataLow <- tm_map(dataCorpus,content_transformer(tolower))
dataLow
dataLow <- tm_map(dataCorpus$DrJekyllAndMrHyde.txt,content_transformer(tolower))
# Create a VCorpus - I (Voltatile corpus aka collection of documents containing natural language text
# using the infrastructure of the package tm)
# Contains all files in working directory
dataCorpus <- VCorpus(DirSource("text/",ignore.case = TRUE,mode="text"))
dataCorpus
inspect(dataCorpus)
dataCorpus[1]
dataCorpus[1]$DrJekyllAndMrHyde.txt
dataCorpus[1]
dataDTM <- DocumentTermMatrix(dataCorpus)
dataDTM
dataDTM$dimnames
inspect(dataDTM[1,100])
dataDTM$i
dataDTM$1
dataDTM[1]
dataDTM[1,10]
dataDTM$ncol
dataDTM$nrow
dataDTM[20,1]
dataDTM[1,100]
data1TF <- termFreq(data1)
data1TF
data1TF[1]
data1TF[1:100]
data1DF[1:100]
data1DF[1]
dataLow <- tm_map(dataCorpus,content_transformer(tolower))
dataLow
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*","",x)
dataCl <- tm_map(dataLow,content_transformer(removeNumPunct))
dataCl
toSpace <- content_transformer(function (x,pattern) gsub(pattern,"",x))
dataCl <- tm_map(dataCl,toSpace,"/")
dataCl <- tm_map(dataCl,toSpace,"@")
dataCl <- tm_map(dataCl,toSpace,"\\|")
myStopWords <- c(stopwords('english'))
myStopWords
dataCl <- tm_map(dataCl,removeWords,myStopWords)
inspect(dataStop[1:3])
str(dataStop)
dataCl
dataClTF <- termFreq(dataCl)
dataClDTM <- DocumentTermMatrix(dataCl)
dataClDTM
inpsect(dataClDTM[10,1])
inspect(dataClDTM[10,1])
inspect(dataClDTM[1,100])
inspect(dataClDTM[1,1:100])
dataClTDM <- TermDocumentMatrix(dataCl)
dataClTDM
inspect(dataClTDM)
inspect(dataClDTM)
inspect(dataClTDM)
inspect(dataClTDM)
inspect(dataClDTM)
myStopWords <- c(stopwords('english'))
myStopWords
freqTerms <- findFreqTerms(dataClDTM,lowfreq=4)
freqTerms
freqTerms <- findFreqTerms(dataClDTM,lowfreq=5)
freqTerms
findFreqTerms(dataClDTM,lowfreq=5)
findFreqTerms(dataClDTM,lowfreq=10)
findFreqTerms(dataClDTM,lowfreq=11)
findFreqTerms(dataClDTM,lowfreq=100)
findFreqTerms(dataClDTM,lowfreq=90)
findFreqTerms(dataClDTM,lowfreq=80)
findFreqTerms(dataClDTM,lowfreq=70)
findFreqTerms(dataClDTM,lowfreq=60)
findFreqTerms(dataClDTM,lowfreq=50)
findFreqTerms(dataClDTM,lowfreq=40)
findFreqTerms(dataClDTM,lowfreq=30)
findFreqTerms(dataClDTM,lowfreq=20)
findFreqTerms(dataClDTM,lowfreq=10)
findFreqTerms(dataClDTM,lowfreq=50)
findFreqTerms(dataClDTM,lowfreq=5)
findFreqTerms(dataClDTM,lowfreq=1)
statesAssoc <- findAssocs(dataClDTM,"states",0.5)
statesAssoc
statesAssoc <- findAssocs(dataClDTM,"die",0.5)
statesAssoc
statesAssoc <- findAssocs(dataClTDM,"die",0.5)
statesAssoc
statesAssoc <- findAssocs(dataClTDM,"die",0.1)
statesAssoc
statesAssoc <- findAssocs(dataCl,"die",0.1)
statesAssoc
statesAssoc <- findAssocs(dataClDTM,"die",0.1)
statesAssoc
findAssocs(dataClDTM,"die",0.1)
findAssocs(dataClDTM,"lawyer",0.1)
findAssocs(dataClDTM,"lawyer",1)
findAssocs(dataClDTM,"",1)
dataClDTM
df <- as.data.frame(dataClDTM)
df <- as.data.frame(dataClTDM)
findAssocs(dataClDTM,"i",1)
findAssocs(dataClDTM,"i",0.1)
dataClDTM$dimnames
findAssocs(dataClDTM,"dimnames",0.1)
findAssocs(dataClDTM$dimnames,"dimnames",0.1)
dataClDTM$dimnames
dataClDTM$dimnames["object"]
dataClDTM["object"]
dataClDTM$dimnames[997]
dataClDTM$dimnames[1,997]
dataClDTM$dimnames[1,9]
dataClDTM$dimnames[1,1]
dataClDTM$dimnames[1]
dataClDTM$dimnames[0]
dataClDTM$dimnames[2]
dataClDTM$dimnames[3]
dataClDTM$dimnames[2]
dataClDTM$dimnames[2,"destiny"]
dataClDTM$dimnames[2]
dataClDTM$dimnames[2]$Terms
dataClDTM$dimnames[2]$Terms[1]
dataClDTM$dimnames[2]$Terms["desire"]
dataClDTM$dimnames[2]$Terms[1]
dataClDTM$dimnames[2]$Terms[2]
dataClDTM$dimnames[2]$Terms[3]
dataClDTM$dimnames[2]$Terms[4]
for(var in 1:100){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:100){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:1000){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:10000){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:2000){
print(dataClDTM$dimnames[2]$Terms[var])
}
statesAssoc <- findAssocs(dataClDTM,"dimnames[2]$Terms",0.1)
statesAssoc
for(var in 1:2000){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:2000){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:2000){
print(dataClDTM$dimnames[2]$Terms[var])
}
termFreq1 <- rowSums(as.matrix(dataClDTM))
termFreq1
for(var in 1:13411){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:5000){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:4000){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:4500){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:4400){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:4300){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:4250){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:4260){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:4270){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:4275){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:4280){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:4285){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:4283){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:4281){
print(dataClDTM$dimnames[2]$Terms[var])
}
for(var in 1:4280){
print(dataClDTM$dimnames[2]$Terms[var])
}
termFreq1 <- rowSums(as.matrix(dataClDTM))
termFreq1
termFreq1Sub <- subset(termFreq1, termFreq1 >= 6)
termFre1Sub
termFreq1Sub
termFreq1Sub <- subset(termFreq1, termFreq1 >= 1)
termFreq1Sub
termFreq1Sub <- subset(termFreq1, termFreq >= 6)
termFreq1Sub <- subset(termFreq1, termFreq1 >= 6)
termFreq1Sub <- subset(termFreq1, termFreq1 >= 6)
termFreq1Sub
termFreq1Sub <- subset(termFreq1, termFreq1 >= 1)
termFreq1Sub
termFreq1
termFreq1 <- rowSums(as.matrix(dataClDTM[1]))
termFreq1
termFreq1 <- rowSums(as.matrix(dataClDTM$dimnames[2]))
termFreq1 <- rowSums(as.matrix(dataClDTM$dimnames[2]$Terms))
termFreq1
termFreq1 <- rowSums(as.matrix(dataClDTM$dimnames[2]$Terms[1:100]))
termFreq1
termFreq1Sub
termFreq1DF <- as.data.frame(names(termFreq1),freq=termFreq1)
termFre1
termFreq1DF
termFreq1DF <- as.data.frame(names(termFreq1[1]),freq=termFreq1)
termFreq1DF
project_data
inspect(project_data)
VCorpus(project_data)
