a = 49
sqrt(a)
a = "The dog ate my homework."
sub("dog", "cat", a)
a = (1+1 == 3)
a
a = c(1, 2, 3)
a*2
a<-matric(data=0, nr=1, nc=3)
a<-matrix(data=0, nr=1, nc=3)
a<-matrix(data=0, nr=1, nc=3)
a = c(1, 2, 3)
a<-matrix(data=0, nr=1, nc=3)
doe = list(name="john", age=28, married=F)
doe$name
doe$age
install.packages("readr")
clear
cls
ls
install.packages("igraph")
install.packages("igraphdata")
install.packages("SNA")
install.packages("sna")
install.packages("rgraph")
load("C:/Users/parmv/Desktop/csci3907/Project3BigData/WD/.RData")
setwd("C:/Users/parmv/Desktop/csci3907/Project3BigData")
# install.packages("tm")
library(tm)
install.packages("tm")
library(tm)
# Load text file
project_data <- read.delim("DrJekyllAndMrHyde.txt")
setwd("C:/Users/parmv/Desktop/csci3907/Project3BigData/WD")
install.packages("tm")
install.packages("tm")
library(tm)
# Load text file
project_data <- read.delim("DrJekyllAndMrHyde.txt")
project_data
# Check numrows
nrow(project_data)
# Check head
head(project_data)
# Create a VCorpus - I (Voltatile corpus aka collection of documents containing natural language text
# using the infrastructure of the package tm)
# Contains all files in working directory
dataCorpus <- VCorpus(DirSource(".",ignore.case = TRUE,mode="text"))
dataCorpus
inspect(dataCorpus)
str(dataCorpus)
data1 <- dataCorpus[[1]]
data1
dataDTM <- DocumentTermMatrix(dataCorpus)
dataDTM
inspect(dataDTM[1,1:6537])
dataLow <- tm_map(dataCorpus,content_transformer(tolower))
dataLow
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*","",x)
dataCl <- tm_map(dataLow,content_transformer(removeNumPunct))
toSpace <- content_transformer(function (x,pattern) gsub(pattern,"",x))
docs <- tm_map(dataCl,toSpace,"/")
docs <- tm_map(dataCl,toSpace,"@")
docs <- tm_map(dataCl,toSpace,"\\|")
myStopWords <- c(stopwords('english'))
myStopWords
SATstop <- tm_map(SATcl, removeWords, myStopWords)
inspect(SATstop[1:3])
SATstop <- tm_map(SATcl, removeWords, myStopWords)
inspect(SATstop[1:3])
DATAstop <- tm_map(DATAcl, removeWords, myStopWords)
DATAstop <- tm_map(dataCl, removeWords, myStopWords)
inspect(DATAstop[1:3])
DATAtdm2 <- TermDocumentMatrix(DATAstop, control = list(wordlengths = c(1,Inf)))
DATAtdm2
freqTerms <- findFreqTerms(DATAtdm2, lowfreq = 4)
freqTerms
statesAssoc <- findAssocs(DATAtdm2, "states", 0.5)
statesAssoc
termFreq <- rowSums(as.matrix(DATAtdm2))
termFreqSub <- subset(termFreq, termFreq >= 6)
termFreqdf <- as.data.frame(names(termFreq), freq = termFreq)
termFreq
DATAtdm2
sparsetdm2 <- removeSparseTerms(DATAtdm2, sparse = 0.75)
inspect(sparsetdm2)
sparsetdm2
test1 <- DATAstop[[1]]
inspect(test1)
fit <- hclust(distMatrix, method="ward.D2")
fit <- hclust(distMatrix, method="ward.D2")
plot(fit)
m1 <- as.matrix(DATAm)
m1 <- as.matrix(DATAtdm2)
word.freq <- sort(rowSums(m1), decreasing = T)
word.freq
install.packages("tm")
install.packages("tm")
install.packages("tm")
install.packages("tm")
install.packages("tm")
install.packages("wordcloud")
library(tm)
library(wordcloud)
# Load text file
project_data <- read.delim("DrJekyllAndMrHyde.txt")
project_data
# Check numrows
nrow(project_data)
# Check head
head(project_data)
dataCorpus
inspect(dataCorpus)
str(dataCorpus)
data1 <- dataCorpus[[1]]
# Create a VCorpus - I (Voltatile corpus aka collection of documents containing natural language text
# using the infrastructure of the package tm)
# Contains all files in working directory
dataCorpus <- VCorpus(DirSource(".",ignore.case = TRUE,mode="text"))
data1
dataDTM <- DocumentTermMatrix(dataCorpus)
dataDTM
dataLow <- tm_map(dataCorpus,content_transformer(tolower))
inspect(dataDTM[1,1:6537])
dataLow
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*","",x)
dataCl <- tm_map(dataLow,content_transformer(removeNumPunct))
toSpace <- content_transformer(function (x,pattern) gsub(pattern,"",x))
docs <- tm_map(dataCl,toSpace,"/")
docs <- tm_map(dataCl,toSpace,"@")
docs <- tm_map(dataCl,toSpace,"\\|")
myStopWords <- c(stopwords('english'))
myStopWords
DATAstop <- tm_map(dataCl, removeWords, myStopWords)
inspect(DATAstop[1:3])
DATAtdm2 <- TermDocumentMatrix(DATAstop, control = list(wordlengths = c(1,Inf)))
DATAtdm2
freqTerms <- findFreqTerms(DATAtdm2, lowfreq = 4)
statesAssoc <- findAssocs(DATAtdm2, "states", 0.5)
freqTerms
statesAssoc
termFreq <- rowSums(as.matrix(DATAtdm2))
termFreqSub <- subset(termFreq, termFreq >= 6)
termFreqdf <- as.data.frame(names(termFreq), freq = termFreq)
DATAtdm2
termFreq
sparsetdm2 <- removeSparseTerms(DATAtdm2, sparse = 0.75)
inspect(sparsetdm2)
sparsetdm2
test1 <- DATAstop[[1]]
inspect(test1)
m1 <- as.matrix(DATAtdm2)
word.freq <- sort(rowSums(m1), decreasing = T)
word.freq
pal <- brewer.pal(9, "BuGn")
pal <- pal[-(1:4)]
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, random.order = F, colors = pal)
pal <- pal[-(1:4)]
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 5, random.order = F, colors = pal)
pal <- pal[-(1:4)]
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 10, random.order = F, colors = pal)
pal <- brewer.pal(9, "BuGn")
pal <- pal[-(1:4)]
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 10, random.order = F, colors = pal)
dataDTM<-DocumentTermMatrix(DATAstop)
freq<-colSums(as.matrix(dataDTM))
dataDTM
length(freq)
ord <- order(freq, decreasing = TRUE)
freq[head(ord)]
freq[tail(ord)]
DATAdtmr <- DocumentTermMatrix(DATAstop, control=list(wordLengths=c(4, 20)))
DATAdtmr
freqr <- colSums(as.matrix(dtmr))
ordr <- order(freqr, decreasing = TRUE)
freqr[head(ordr)]
freqr[tail(ordr)]
fit <- hclust(dataDTM, method="ward.D2")
plot(fit)
